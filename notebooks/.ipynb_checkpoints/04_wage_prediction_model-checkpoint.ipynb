{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wage Prediction Model\n",
    "\n",
    "This notebook develops a predictive model for wages using PUMS (Public Use Microdata Sample) data.\n",
    "\n",
    "## Features Used:\n",
    "- **Geographic**: State (st), PUMA\n",
    "- **Demographics**: Age (agep), Sex (sex), Race (rac1p), Hispanic origin (hisp)\n",
    "- **Education**: Educational attainment (schl), Field of degree (fod1p)\n",
    "- **Employment**: Class of worker (cow), Hours worked (wkhp), Weeks worked (wkwn)\n",
    "- **Occupation**: Occupation code (occp), Industry code (indp)\n",
    "- **Derived**: Experience (estimated from age and education)\n",
    "\n",
    "## Target Variable:\n",
    "- **WAGP**: Wages/salary income past 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from codebook import (\n",
    "    EDUCATION_CATEGORIES, \n",
    "    SEX_VALUES, \n",
    "    RAC1P_VALUES,\n",
    "    COW_VALUES,\n",
    "    STATE_CODES,\n",
    "    get_education_category,\n",
    "    get_value_label\n",
    ")\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load person-level PUMS data\n",
    "data_path = Path.cwd().parent / 'data' / 'pums_person_2023.csv'\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns available: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic statistics for wage variable\n",
    "print(\"Wage (WAGP) Statistics:\")\n",
    "print(df['wagp'].describe())\n",
    "print(f\"\\nNull values: {df['wagp'].isna().sum()} ({df['wagp'].isna().mean()*100:.1f}%)\")\n",
    "print(f\"Zero wages: {(df['wagp'] == 0).sum()} ({(df['wagp'] == 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "### 2.1 Filter to Working Population\n",
    "We'll focus on:\n",
    "- Workers with positive wages\n",
    "- Prime working age (25-64)\n",
    "- Employed individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to working population with positive wages\n",
    "df_workers = df[\n",
    "    (df['wagp'] > 0) &                    # Positive wages\n",
    "    (df['agep'] >= 25) & (df['agep'] <= 64) &  # Prime working age\n",
    "    (df['esr'].isin([1, 2, 4, 5]))        # Employed (civilian or armed forces)\n",
    "].copy()\n",
    "\n",
    "print(f\"Original dataset: {len(df):,} records\")\n",
    "print(f\"Filtered workers: {len(df_workers):,} records\")\n",
    "print(f\"Retention rate: {len(df_workers)/len(df)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of wages\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Raw wages\n",
    "axes[0].hist(df_workers['wagp'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Wages ($)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Wages')\n",
    "axes[0].axvline(df_workers['wagp'].median(), color='red', linestyle='--', label=f'Median: ${df_workers[\"wagp\"].median():,.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Log wages\n",
    "df_workers['log_wagp'] = np.log1p(df_workers['wagp'])\n",
    "axes[1].hist(df_workers['log_wagp'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1].set_xlabel('Log(Wages + 1)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Log Wages')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education years mapping (approximate)\n",
    "EDUCATION_YEARS = {\n",
    "    1: 0, 2: 0, 3: 0,           # No schooling / preschool / kindergarten\n",
    "    4: 1, 5: 2, 6: 3, 7: 4,     # Grades 1-4\n",
    "    8: 5, 9: 6, 10: 7, 11: 8,   # Grades 5-8\n",
    "    12: 9, 13: 10, 14: 11, 15: 11,  # Grades 9-12 (no diploma)\n",
    "    16: 12, 17: 12,             # High school diploma / GED\n",
    "    18: 13, 19: 14,             # Some college\n",
    "    20: 14,                     # Associate's\n",
    "    21: 16,                     # Bachelor's\n",
    "    22: 18,                     # Master's\n",
    "    23: 20,                     # Professional\n",
    "    24: 21                      # Doctorate\n",
    "}\n",
    "\n",
    "# Create derived features\n",
    "df_workers['education_years'] = df_workers['schl'].map(EDUCATION_YEARS)\n",
    "df_workers['education_category'] = df_workers['schl'].apply(get_education_category)\n",
    "\n",
    "# Experience = Age - Education Years - 6 (school start age)\n",
    "df_workers['experience'] = df_workers['agep'] - df_workers['education_years'] - 6\n",
    "df_workers['experience'] = df_workers['experience'].clip(lower=0)  # No negative experience\n",
    "\n",
    "# Experience squared (for diminishing returns)\n",
    "df_workers['experience_sq'] = df_workers['experience'] ** 2\n",
    "\n",
    "# Age squared\n",
    "df_workers['age_sq'] = df_workers['agep'] ** 2\n",
    "\n",
    "# Sex as binary\n",
    "df_workers['is_female'] = (df_workers['sex'] == 2).astype(int)\n",
    "\n",
    "# Occupation category (first 2 digits of OCCP for major group)\n",
    "df_workers['occp_major'] = df_workers['occp'].astype(str).str[:2]\n",
    "\n",
    "# Industry category (first 2 digits of INDP for major sector)\n",
    "df_workers['indp_major'] = df_workers['indp'].astype(str).str[:2]\n",
    "\n",
    "print(\"Feature engineering complete!\")\n",
    "print(f\"\\nNew features: education_years, education_category, experience, experience_sq, age_sq, is_female, occp_major, indp_major\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in key features\n",
    "key_features = ['agep', 'sex', 'schl', 'wkhp', 'st', 'occp', 'indp', 'cow', 'education_years', 'experience']\n",
    "missing_summary = df_workers[key_features].isnull().sum()\n",
    "print(\"Missing values in key features:\")\n",
    "print(missing_summary[missing_summary > 0])\n",
    "print(f\"\\nTotal records: {len(df_workers):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "# Numeric features\n",
    "numeric_features = [\n",
    "    'agep',           # Age\n",
    "    'experience',     # Derived experience\n",
    "    'experience_sq',  # Experience squared\n",
    "    'wkhp',           # Hours worked per week\n",
    "    'education_years' # Years of education\n",
    "]\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = [\n",
    "    'sex',              # Sex (1=Male, 2=Female)\n",
    "    'education_category', # Education level\n",
    "    'st',               # State\n",
    "    'cow',              # Class of worker\n",
    "    'occp_major',       # Occupation major group\n",
    "    'indp_major'        # Industry major sector\n",
    "]\n",
    "\n",
    "# Target variable\n",
    "target = 'log_wagp'  # Using log wages for better distribution\n",
    "\n",
    "# Create modeling dataset\n",
    "all_features = numeric_features + categorical_features\n",
    "df_model = df_workers[all_features + [target, 'wagp', 'pwgtp']].dropna()\n",
    "\n",
    "print(f\"Modeling dataset: {len(df_model):,} records\")\n",
    "print(f\"Features: {len(all_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of categorical features\n",
    "print(\"Categorical Feature Cardinality:\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"  {feat}: {df_model[feat].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wage by education level\n",
    "edu_order = ['Less than high school', 'High school diploma', 'Some college', \n",
    "             \"Associate's degree\", \"Bachelor's degree\", \"Master's degree\", \n",
    "             'Professional degree', 'Doctorate degree']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "edu_wages = df_model.groupby('education_category')['wagp'].median().reindex(edu_order)\n",
    "bars = ax.bar(range(len(edu_wages)), edu_wages.values, color=plt.cm.viridis(np.linspace(0, 1, len(edu_wages))))\n",
    "ax.set_xticks(range(len(edu_wages)))\n",
    "ax.set_xticklabels(edu_wages.index, rotation=45, ha='right')\n",
    "ax.set_ylabel('Median Wages ($)')\n",
    "ax.set_title('Median Wages by Education Level')\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, edu_wages.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000, \n",
    "            f'${val:,.0f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wage by sex\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "sex_labels = {1: 'Male', 2: 'Female'}\n",
    "df_model['sex_label'] = df_model['sex'].map(sex_labels)\n",
    "df_model.boxplot(column='wagp', by='sex_label', ax=axes[0])\n",
    "axes[0].set_title('Wage Distribution by Sex')\n",
    "axes[0].set_xlabel('Sex')\n",
    "axes[0].set_ylabel('Wages ($)')\n",
    "axes[0].set_ylim(0, 200000)\n",
    "plt.suptitle('')\n",
    "\n",
    "# Median comparison\n",
    "sex_wages = df_model.groupby('sex_label')['wagp'].agg(['median', 'mean'])\n",
    "x = range(len(sex_wages))\n",
    "width = 0.35\n",
    "axes[1].bar([i - width/2 for i in x], sex_wages['median'], width, label='Median', color='steelblue')\n",
    "axes[1].bar([i + width/2 for i in x], sex_wages['mean'], width, label='Mean', color='coral')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(sex_wages.index)\n",
    "axes[1].set_ylabel('Wages ($)')\n",
    "axes[1].set_title('Mean vs Median Wages by Sex')\n",
    "axes[1].legend()\n",
    "axes[1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gender wage gap\n",
    "male_median = sex_wages.loc['Male', 'median']\n",
    "female_median = sex_wages.loc['Female', 'median']\n",
    "gap = (male_median - female_median) / male_median * 100\n",
    "print(f\"\\nGender Wage Gap: {gap:.1f}% (Female median is {100-gap:.1f}% of Male median)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wage vs Experience\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Sample for visualization\n",
    "sample = df_model.sample(min(5000, len(df_model)), random_state=42)\n",
    "ax.scatter(sample['experience'], sample['wagp'], alpha=0.3, s=10)\n",
    "\n",
    "# Add trend line\n",
    "exp_bins = pd.cut(df_model['experience'], bins=20)\n",
    "exp_median = df_model.groupby(exp_bins)['wagp'].median()\n",
    "exp_centers = [(interval.left + interval.right) / 2 for interval in exp_median.index]\n",
    "ax.plot(exp_centers, exp_median.values, 'r-', linewidth=3, label='Median trend')\n",
    "\n",
    "ax.set_xlabel('Years of Experience')\n",
    "ax.set_ylabel('Wages ($)')\n",
    "ax.set_title('Wages vs Experience')\n",
    "ax.set_ylim(0, 300000)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_model[all_features].copy()\n",
    "y = df_model[target].copy()\n",
    "sample_weights = df_model['pwgtp'].copy()  # Person weights\n",
    "\n",
    "# Convert categorical features to string type\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, sample_weights, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} samples\")\n",
    "print(f\"Test set: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit preprocessor and transform data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Processed feature dimensions: {X_train_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to compare\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.01),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    if hasattr(model, 'sample_weight'):\n",
    "        model.fit(X_train_processed, y_train, sample_weight=w_train)\n",
    "    else:\n",
    "        model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    \n",
    "    # Convert back from log scale for interpretable metrics\n",
    "    y_test_actual = np.expm1(y_test)\n",
    "    y_pred_actual = np.expm1(y_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred_actual))\n",
    "    mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "    r2 = r2_score(y_test, y_pred)  # R2 on log scale\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'RMSE ($)': rmse,\n",
    "        'MAE ($)': mae,\n",
    "        'R² (log scale)': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"  RMSE: ${rmse:,.0f}, MAE: ${mae:,.0f}, R²: {r2:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# R² comparison\n",
    "axes[0].barh(results_df['Model'], results_df['R² (log scale)'], color='steelblue')\n",
    "axes[0].set_xlabel('R² Score')\n",
    "axes[0].set_title('Model Comparison: R² (higher is better)')\n",
    "axes[0].set_xlim(0, 1)\n",
    "\n",
    "# RMSE comparison\n",
    "axes[1].barh(results_df['Model'], results_df['RMSE ($)'], color='coral')\n",
    "axes[1].set_xlabel('RMSE ($)')\n",
    "axes[1].set_title('Model Comparison: RMSE (lower is better)')\n",
    "axes[1].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "# MAE comparison\n",
    "axes[2].barh(results_df['Model'], results_df['MAE ($)'], color='green')\n",
    "axes[2].set_xlabel('MAE ($)')\n",
    "axes[2].set_title('Model Comparison: MAE (lower is better)')\n",
    "axes[2].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing\n",
    "cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "all_feature_names = list(numeric_features) + list(cat_feature_names)\n",
    "\n",
    "# Use Random Forest for feature importance\n",
    "rf_model = models['Random Forest']\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Create importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Show top 20 features\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(importance_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top features\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "top_n = 20\n",
    "top_features = importance_df.head(top_n)\n",
    "\n",
    "ax.barh(range(top_n), top_features['Importance'].values, color='steelblue')\n",
    "ax.set_yticks(range(top_n))\n",
    "ax.set_yticklabels(top_features['Feature'].values)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title(f'Top {top_n} Feature Importances (Random Forest)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate importance by feature category\n",
    "category_importance = {}\n",
    "\n",
    "# Numeric features\n",
    "for feat in numeric_features:\n",
    "    idx = all_feature_names.index(feat)\n",
    "    category_importance[feat] = importances[idx]\n",
    "\n",
    "# Categorical features (sum of all one-hot encoded columns)\n",
    "for cat_feat in categorical_features:\n",
    "    total_imp = sum(importances[i] for i, name in enumerate(all_feature_names) if name.startswith(cat_feat + '_'))\n",
    "    category_importance[cat_feat] = total_imp\n",
    "\n",
    "# Sort and display\n",
    "cat_imp_df = pd.DataFrame([\n",
    "    {'Feature Category': k, 'Total Importance': v} \n",
    "    for k, v in category_importance.items()\n",
    "]).sort_values('Total Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Category Importance:\")\n",
    "print(cat_imp_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(cat_imp_df['Feature Category'], cat_imp_df['Total Importance'], color='teal')\n",
    "ax.set_xlabel('Total Importance')\n",
    "ax.set_title('Feature Category Importance')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best model (Gradient Boosting or Random Forest based on results)\n",
    "best_model = models['Gradient Boosting']\n",
    "y_pred = best_model.predict(X_test_processed)\n",
    "\n",
    "# Convert back from log scale\n",
    "y_test_actual = np.expm1(y_test)\n",
    "y_pred_actual = np.expm1(y_pred)\n",
    "\n",
    "# Actual vs Predicted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Scatter plot\n",
    "sample_idx = np.random.choice(len(y_test_actual), min(5000, len(y_test_actual)), replace=False)\n",
    "axes[0].scatter(y_test_actual.iloc[sample_idx], y_pred_actual[sample_idx], alpha=0.3, s=10)\n",
    "axes[0].plot([0, 300000], [0, 300000], 'r--', label='Perfect prediction')\n",
    "axes[0].set_xlabel('Actual Wages ($)')\n",
    "axes[0].set_ylabel('Predicted Wages ($)')\n",
    "axes[0].set_title('Actual vs Predicted Wages')\n",
    "axes[0].set_xlim(0, 300000)\n",
    "axes[0].set_ylim(0, 300000)\n",
    "axes[0].legend()\n",
    "\n",
    "# Residuals distribution\n",
    "residuals = y_test_actual - y_pred_actual\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(0, color='red', linestyle='--', label='Zero error')\n",
    "axes[1].set_xlabel('Residual (Actual - Predicted) ($)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Prediction Errors')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean Residual: ${residuals.mean():,.0f}\")\n",
    "print(f\"Median Residual: ${residuals.median():,.0f}\")\n",
    "print(f\"Std of Residuals: ${residuals.std():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Wage Predictions by Demographic Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataframe with predictions\n",
    "test_results = X_test.copy()\n",
    "test_results['actual_wage'] = y_test_actual.values\n",
    "test_results['predicted_wage'] = y_pred_actual\n",
    "test_results['residual'] = test_results['actual_wage'] - test_results['predicted_wage']\n",
    "\n",
    "# Analyze by education\n",
    "edu_analysis = test_results.groupby('education_category').agg({\n",
    "    'actual_wage': ['mean', 'median'],\n",
    "    'predicted_wage': ['mean', 'median'],\n",
    "    'residual': 'mean'\n",
    "}).round(0)\n",
    "\n",
    "edu_analysis.columns = ['Actual Mean', 'Actual Median', 'Predicted Mean', 'Predicted Median', 'Mean Error']\n",
    "edu_analysis = edu_analysis.reindex(edu_order)\n",
    "\n",
    "print(\"Wage Predictions by Education Level:\")\n",
    "print(edu_analysis.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze by sex\n",
    "sex_analysis = test_results.groupby('sex').agg({\n",
    "    'actual_wage': ['mean', 'median'],\n",
    "    'predicted_wage': ['mean', 'median'],\n",
    "    'residual': 'mean'\n",
    "}).round(0)\n",
    "\n",
    "sex_analysis.columns = ['Actual Mean', 'Actual Median', 'Predicted Mean', 'Predicted Median', 'Mean Error']\n",
    "sex_analysis.index = sex_analysis.index.map(lambda x: 'Male' if x == '1' else 'Female')\n",
    "\n",
    "print(\"\\nWage Predictions by Sex:\")\n",
    "print(sex_analysis.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model and preprocessor\n",
    "model_dir = Path.cwd().parent / 'models'\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(best_model, model_dir / 'wage_prediction_model.joblib')\n",
    "joblib.dump(preprocessor, model_dir / 'wage_preprocessor.joblib')\n",
    "\n",
    "print(f\"Model saved to {model_dir / 'wage_prediction_model.joblib'}\")\n",
    "print(f\"Preprocessor saved to {model_dir / 'wage_preprocessor.joblib'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"WAGE PREDICTION MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset: PUMS 2023 Person-level data\")\n",
    "print(f\"Sample size: {len(df_model):,} workers (age 25-64, positive wages)\")\n",
    "print(f\"\\nFeatures used: {len(all_features)}\")\n",
    "print(f\"  - Numeric: {numeric_features}\")\n",
    "print(f\"  - Categorical: {categorical_features}\")\n",
    "print(f\"\\nBest Model: Gradient Boosting Regressor\")\n",
    "print(f\"  - R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"  - RMSE: ${np.sqrt(mean_squared_error(y_test_actual, y_pred_actual)):,.0f}\")\n",
    "print(f\"  - MAE: ${mean_absolute_error(y_test_actual, y_pred_actual):,.0f}\")\n",
    "print(f\"\\nTop 5 Important Features:\")\n",
    "for i, row in cat_imp_df.head(5).iterrows():\n",
    "    print(f\"  {row['Feature Category']}: {row['Total Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wage(age, sex, education_category, state, cow, occp_major, indp_major, wkhp, education_years=None):\n",
    "    \"\"\"\n",
    "    Predict wage for a given set of characteristics.\n",
    "    \n",
    "    Parameters:\n",
    "    - age: Age in years\n",
    "    - sex: 1 for Male, 2 for Female\n",
    "    - education_category: e.g., \"Bachelor's degree\"\n",
    "    - state: State code (e.g., '06' for California)\n",
    "    - cow: Class of worker (1-9)\n",
    "    - occp_major: Occupation major group (2-digit code)\n",
    "    - indp_major: Industry major sector (2-digit code)\n",
    "    - wkhp: Hours worked per week\n",
    "    - education_years: Years of education (optional, will be estimated)\n",
    "    \"\"\"\n",
    "    # Estimate education years if not provided\n",
    "    edu_years_map = {\n",
    "        'Less than high school': 10,\n",
    "        'High school diploma': 12,\n",
    "        'Some college': 14,\n",
    "        \"Associate's degree\": 14,\n",
    "        \"Bachelor's degree\": 16,\n",
    "        \"Master's degree\": 18,\n",
    "        'Professional degree': 20,\n",
    "        'Doctorate degree': 21\n",
    "    }\n",
    "    \n",
    "    if education_years is None:\n",
    "        education_years = edu_years_map.get(education_category, 12)\n",
    "    \n",
    "    experience = max(0, age - education_years - 6)\n",
    "    \n",
    "    # Create input dataframe\n",
    "    input_data = pd.DataFrame([{\n",
    "        'agep': age,\n",
    "        'experience': experience,\n",
    "        'experience_sq': experience ** 2,\n",
    "        'wkhp': wkhp,\n",
    "        'education_years': education_years,\n",
    "        'sex': str(sex),\n",
    "        'education_category': education_category,\n",
    "        'st': str(state),\n",
    "        'cow': str(cow),\n",
    "        'occp_major': str(occp_major),\n",
    "        'indp_major': str(indp_major)\n",
    "    }])\n",
    "    \n",
    "    # Preprocess and predict\n",
    "    input_processed = preprocessor.transform(input_data)\n",
    "    log_wage_pred = best_model.predict(input_processed)[0]\n",
    "    wage_pred = np.expm1(log_wage_pred)\n",
    "    \n",
    "    return wage_pred\n",
    "\n",
    "# Example predictions\n",
    "print(\"Example Wage Predictions:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example 1: Young male with bachelor's degree in tech\n",
    "pred1 = predict_wage(age=30, sex=1, education_category=\"Bachelor's degree\", \n",
    "                     state='06', cow=1, occp_major='15', indp_major='51', wkhp=40)\n",
    "print(f\"\\n30-year-old male, Bachelor's degree, Tech industry (CA):\")\n",
    "print(f\"  Predicted annual wage: ${pred1:,.0f}\")\n",
    "\n",
    "# Example 2: Female with master's degree in healthcare\n",
    "pred2 = predict_wage(age=40, sex=2, education_category=\"Master's degree\", \n",
    "                     state='36', cow=2, occp_major='29', indp_major='62', wkhp=40)\n",
    "print(f\"\\n40-year-old female, Master's degree, Healthcare (NY):\")\n",
    "print(f\"  Predicted annual wage: ${pred2:,.0f}\")\n",
    "\n",
    "# Example 3: High school graduate in manufacturing\n",
    "pred3 = predict_wage(age=35, sex=1, education_category=\"High school diploma\", \n",
    "                     state='48', cow=1, occp_major='51', indp_major='33', wkhp=45)\n",
    "print(f\"\\n35-year-old male, High school diploma, Manufacturing (TX):\")\n",
    "print(f\"  Predicted annual wage: ${pred3:,.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
